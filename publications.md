---
layout: page
permalink: /publications/index.html
title: Publications
---

> (â€ : equal contribution, ~: corresponding author)

## Selected Publications
<p class="justify-align">
<ul>
  <li><b>Few-shot Object Detection via Dual-domain Feature Fusion and Patch-level Attention</b><br>
    <p style="font-family: Arial, sans-serif; font-size: 16px;">
      <b>Guangli Ren</b>; Jierui Liu; Mengyao Wang; Peiyu Guan~; Zhiqiang Cao; Junzhi Yu; Tsinghua Science and Technology, vol. 30, no. 3, June. 2025.
    </p>
  </li>
  <li><a href="https://rengl.github.io/mypaper/papers/iros2017.pdf"><b>A fast search algorithm based on image pyramid for robotic grasping</b></a>. <br><b>Guangli Ren</b>; Zhenzhou Shao; Yong Guan; Ying Qu; Jindong Tan; Hongxing Wei; Guofeng Tong~; 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Vancouver, BC, Canada, 2017, pp. 6520-6525.
  </li>
  <div class="button">
      <a href="https://rengl.github.io/mypaper/papers/iros2017.pdf">arXiv</a>
  </div>

  <li><a href="https://rengl.github.io/mypaper/papers/pljslam.pdf"><b>PLJ-SLAM Monocular Visual SLAM With Points, Lines, and Junctions of Coplanar Lines</b></a>.<br> <b>Guangli Ren</b>; Zhiqiang Cao; Xilong Liu; Min Tan; Junzhi Yu~<br>in IEEE Sensors Journal, vol. 22, no. 15, pp. 15465-15476, 1 Aug.1, 2022.
  </li>
  <div class="button">
      <a href="https://rengl.github.io/mypaper/papers/pljslam.pdf">arXiv</a>
  </div>

  <li><a href="https://rengl.github.io/mypaper/papers/tdmagnet.pdf"><b>Pixel-Wise Grasp Detection via Twin Deconvolution and Multi-Dimensional Attention</b></a>.<br> <b>Guangli Ren</b>; Wenjie Geng; Peiyu Guan; Zhiqiang Cao; Junzhi Yu~<br>IEEE Transactions on Circuits and Systems for Video Technology, vol. 33, no. 8, pp. 4002-4010, Aug. 2023.
  </li>
  <div class="button">
      <a href="https://rengl.github.io/mypaper/papers/tdmagnet.pdf">arXiv</a>
  </div>

  <li><a href="https://rengl.github.io/mypaper/papers/iros2020.pdf"><b>Batch Normalization Masked Sparse Autoencoder for Robotic Grasping Detection</b></a>.<br> Zhenzhou Shao; Ying Qu; <b>Guangli Ren</b>; Guohui Wang; Yong Guan; Zhiping Shi; Jindong Tan~<br>EEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Las Vegas, NV, USA, 2020, pp. 9614-9619.
  </li>
  <div class="button">
      <a href="https://rengl.github.io/mypaper/papers/iros2020.pdf">arXiv</a>
  </div>

  <li><a href="https://rengl.github.io/mypaper/papers/yyy.pdf"><b>Robot Navigation Based on Situational Awareness</b></a>.<br> Xilong Liu; Zhiqiang Cao; Yingying Yu; <b>Guangli Ren</b>; Junzhi Yu; Min Tan~<br>IEEE Transactions on Cognitive and Developmental Systems, vol. 14, no. 3, pp. 869-881, Sept. 2022.
  </li>
  <div class="button">
      <a href="https://rengl.github.io/mypaper/papers/yyy.pdf">arXiv</a>
  </div>

  <li><a href="https://rengl.github.io/mypaper/papers/gwj.pdf"><b>Adaptive Long-Neck Network With Atrous-Residual Structure for Instance Segmentation</b></a>.<br> Wenjie Geng; Zhiqiang Cao; Peiyu Guan; <b>Guangli Ren</b>; Junzhi Yu; Fengshui Jing~<br>IEEE Sensors Journal, vol. 23, no. 7, pp. 7786-7797, 1 April1, 2023.
  </li>
  <div class="button">
      <a href="https://rengl.github.io/mypaper/papers/gwj.pdf">arXiv</a>
  </div>
</ul>
</p>

<br>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
<tbody>
  <tr onmouseout="cat3d_stop()" onmouseover="cat3d_start()" bgcolor="#ffffd0">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='cat3d_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/cat3d.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/cat3d.jpg' width="160">
        </div>
        <script type="text/javascript">
          function cat3d_start() {
            document.getElementById('cat3d_image').style.opacity = "1";
          }
          function cat3d_stop() {
            document.getElementById('cat3d_image').style.opacity = "0";
          }
          cat3d_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://cat3d.github.io/">
      <span class="papertitle">CAT3D: Create Anything in 3D with Multi-View Diffusion Models</span>
        </a>
        <br>
        <a href="https://ruiqigao.github.io/">Ruiqi Gao</a>*,
        <a href="https://holynski.org/">Aleksander Holynski</a>*, 
        <a href="https://henzler.github.io/">Philipp Henzler</a>,
        <a href="https://github.com/ArthurBrussee">Arthur Brussee</a>, 
        <a href="http://ricardomartinbrualla.com/">Ricardo Martin Brualla</a>, 
        <a href="https://pratulsrinivasan.github.io/">Pratul P. Srinivasan</a>,
        <strong>Jonathan T. Barron</strong>,
        <a href="https://poolio.github.io/">Ben Poole</a>*
        <br>
        <em>NeurIPS</em>, 2024 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
        <br>
        <a href="https://cat3d.github.io/">project page</a>
        /
        <a href="https://arxiv.org/abs/2405.10314">arXiv</a>
        <p></p>
        <p>
        A single model built around diffusion and NeRF that does text-to-3D, image-to-3D, and few-view reconstruction, trains in 1 minute, and renders at 60FPS in a browser.
        </p>
      </td>
    </tr>
</tbody>
</table>
---
<!-- 
## Degree Thesis
-->
